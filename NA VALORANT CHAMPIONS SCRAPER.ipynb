{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c5396c1",
   "metadata": {},
   "source": [
    "# Valorant Match Scraper Prototype\n",
    "This script does the following:\n",
    "1. Retrieve match URLs from the VLR website\n",
    "2. Create headers for two CSV files\n",
    "3. Exports match and game details into two separate CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cf147f",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bedcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from csv import writer\n",
    "import re\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d05f972",
   "metadata": {},
   "source": [
    "### Champions Tour North America Stage 1: Challengers\n",
    "The url in this script was manually retrieved from the VLR website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee97b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.vlr.gg/event/matches/799/champions-tour-north-america-stage-1-challengers/?group=completed\"\n",
    "page = requests.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f7b103",
   "metadata": {},
   "source": [
    "Parsing the HTML tree to get each match URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55d2ebd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "match_urls = []\n",
    "for div in soup.find_all(lambda tag: tag.name == 'div' and tag.get('class') == ['wf-card']):\n",
    "    for link in div.find_all('a'):\n",
    "        match_urls.append(link.get('href'))\n",
    "\n",
    "# Each url in match_url contains the sub-link of each match detail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e3e477",
   "metadata": {},
   "source": [
    "### Prepare the headers for the CSV files\n",
    "This script writes the headers for each CSV file that would be produced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf6ddbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('matches1_NA.csv', 'w') as f:\n",
    "    thewriter = writer(f)\n",
    "    header = ['match_id', 'date', 'time', 'patch_number', 'team0_ID', 'team1_ID', 'team0_score', 'team1_score', 'winner_ID', 'loser_ID',\n",
    "              'player0_ID', 'player1_ID', 'player2_ID', 'player3_ID', 'player4_ID',\n",
    "              'player0_ACS', 'player0_K', 'player0_D', 'player0_A', 'player0_KD', 'player0_KAST', 'player0_ADR', 'player0_HS', 'player0_FK', 'player0_FD', 'player0_FKFD',\n",
    "              'player1_ACS', 'player1_K', 'player1_D', 'player1_A', 'player1_KD', 'player1_KAST', 'player1_ADR', 'player1_HS', 'player1_FK', 'player1_FD', 'player1_FKFD',\n",
    "              'player2_ACS', 'player2_K', 'player2_D', 'player2_A', 'player2_KD', 'player2_KAST', 'player2_ADR', 'player2_HS', 'player2_FK', 'player2_FD', 'player2_FKFD',\n",
    "              'player3_ACS', 'player3_K', 'player3_D', 'player3_A', 'player3_KD', 'player3_KAST', 'player3_ADR', 'player3_HS', 'player3_FK', 'player3_FD', 'player3_FKFD',\n",
    "              'player4_ACS', 'player4_K', 'player4_D', 'player4_A', 'player4_KD', 'player4_KAST', 'player4_ADR', 'player4_HS', 'player4_FK', 'player4_FD', 'player4_FKFD',\n",
    "              'player5_ID', 'player6_ID', 'player7_ID', 'player8_ID', 'player9_ID',\n",
    "              'player5_ACS', 'player5_K', 'player5_D', 'player5_A', 'player5_KD', 'player5_KAST', 'player5_ADR', 'player5_HS', 'player5_FK', 'player5_FD', 'player5_FKFD',\n",
    "              'player6_ACS', 'player6_K', 'player6_D', 'player6_A', 'player6_KD', 'player6_KAST', 'player6_ADR', 'player6_HS', 'player6_FK', 'player6_FD', 'player6_FKFD',\n",
    "              'player7_ACS', 'player7_K', 'player7_D', 'player7_A', 'player7_KD', 'player7_KAST', 'player7_ADR', 'player7_HS', 'player7_FK', 'player7_FD', 'player7_FKFD',\n",
    "              'player8_ACS', 'player8_K', 'player8_D', 'player8_A', 'player8_KD', 'player8_KAST', 'player8_ADR', 'player8_HS', 'player8_FK', 'player8_FD', 'player8_FKFD',\n",
    "              'player9_ACS', 'player9_K', 'player9_D', 'player9_A', 'player9_KD', 'player9_KAST', 'player9_ADR', 'player9_HS', 'player9_FK', 'player9_FD', 'player9_FKFD']\n",
    "    thewriter.writerow(header)\n",
    "    \n",
    "with open('games1_NA.csv', 'w') as f:\n",
    "    thewriter = writer(f)\n",
    "    header = ['match_id', 'map', 'team0_score', 'team1_score', 'winner_ID', 'loser_ID',\n",
    "              'player0_agent', 'player1_agent', 'player2_agent', 'player3_agent', 'player4_agent',\n",
    "              'player0_ID', 'player1_ID', 'player2_ID', 'player3_ID', 'player4_ID',\n",
    "              'player0_ACS', 'player0_K', 'player0_D', 'player0_A', 'player0_KD', 'player0_KAST', 'player0_ADR', 'player0_HS', 'player0_FK', 'player0_FD', 'player0_FKFD',\n",
    "              'player1_ACS', 'player1_K', 'player1_D', 'player1_A', 'player1_KD', 'player1_KAST', 'player1_ADR', 'player1_HS', 'player1_FK', 'player1_FD', 'player1_FKFD',\n",
    "              'player2_ACS', 'player2_K', 'player2_D', 'player2_A', 'player2_KD', 'player2_KAST', 'player2_ADR', 'player2_HS', 'player2_FK', 'player2_FD', 'player2_FKFD',\n",
    "              'player3_ACS', 'player3_K', 'player3_D', 'player3_A', 'player3_KD', 'player3_KAST', 'player3_ADR', 'player3_HS', 'player3_FK', 'player3_FD', 'player3_FKFD',\n",
    "              'player4_ACS', 'player4_K', 'player4_D', 'player4_A', 'player4_KD', 'player4_KAST', 'player4_ADR', 'player4_HS', 'player4_FK', 'player4_FD', 'player4_FKFD',\n",
    "              'player5_agent', 'player6_agent', 'player7_agent', 'player8_agent', 'player9_agent',\n",
    "              'player5_ID', 'player6_ID', 'player7_ID', 'player8_ID', 'player9_ID',\n",
    "              'player5_ACS', 'player5_K', 'player5_D', 'player5_A', 'player5_KD', 'player5_KAST', 'player5_ADR', 'player5_HS', 'player5_FK', 'player5_FD', 'player5_FKFD',\n",
    "              'player6_ACS', 'player6_K', 'player6_D', 'player6_A', 'player6_KD', 'player6_KAST', 'player6_ADR', 'player6_HS', 'player6_FK', 'player6_FD', 'player6_FKFD',\n",
    "              'player7_ACS', 'player7_K', 'player7_D', 'player7_A', 'player7_KD', 'player7_KAST', 'player7_ADR', 'player7_HS', 'player7_FK', 'player7_FD', 'player7_FKFD',\n",
    "              'player8_ACS', 'player8_K', 'player8_D', 'player8_A', 'player8_KD', 'player8_KAST', 'player8_ADR', 'player8_HS', 'player8_FK', 'player8_FD', 'player8_FKFD',\n",
    "              'player9_ACS', 'player9_K', 'player9_D', 'player9_A', 'player9_KD', 'player9_KAST', 'player9_ADR', 'player9_HS', 'player9_FK', 'player9_FD', 'player9_FKFD']\n",
    "    thewriter.writerow(header)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107325a2",
   "metadata": {},
   "source": [
    "### Get data for each match\n",
    "This script iterates over each match in the `match_urls` array, and retrieves the relevant details of that match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46266047",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (232, len(match_urls)):\n",
    "    url = \"https://www.vlr.gg\" + match_urls[i]\n",
    "    page = requests.get(url)\n",
    "\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    # Get Date, and Patch Version contained in Match Header\n",
    "    data = []\n",
    "    data.append(url)\n",
    "    for div in soup.find_all(lambda tag: tag.name == 'div' and tag.get('class') == ['match-header-date']):\n",
    "        date = div.find('div').attrs['data-utc-ts']\n",
    "        time = date.split()[1]\n",
    "        date = date.split()[0]\n",
    "\n",
    "        patchnum = div.find(text=re.compile('Patch')).strip()\n",
    "\n",
    "        data.append(date)\n",
    "        data.append(time)\n",
    "        data.append(patchnum)\n",
    "\n",
    "    # Get Team ID's\n",
    "    teams = []\n",
    "    for div in soup.find_all(lambda tag: tag.name == 'div' and tag.get('class') == ['match-header-vs']):\n",
    "        for link in div.find_all('a', href=True):\n",
    "            teams.append(link['href'])\n",
    "        data.append(teams[0]) \n",
    "        data.append(teams[1])\n",
    "        \n",
    "    # Get Winner and Loser\n",
    "    scores = []\n",
    "    for div in soup.find_all(lambda tag: tag.name == 'div' and tag.get('class') == ['js-spoiler']):\n",
    "        for span in div.find_all('span'):\n",
    "            if (span.attrs['class'])[0] != 'match-header-vs-score-colon':\n",
    "                scores.append((span.text).strip())\n",
    "        data.append(scores[0])\n",
    "        data.append(scores[1])\n",
    "    \n",
    "    # Error correction if scores are invalid\n",
    "    if ((int(scores[0]) == int(scores[1])) or not len(scores)):\n",
    "        print(\"Invalid scores at \", url)\n",
    "        continue\n",
    "    elif int(scores[0]) > int(scores[1]):\n",
    "        data.append(teams[0])\n",
    "        data.append(teams[1])    \n",
    "    else:\n",
    "        data.append(teams[1])\n",
    "        data.append(teams[0])\n",
    "\n",
    "    # Get MAPS\n",
    "    maps = []\n",
    "    for div in soup.find_all('div', class_='vm-stats-gamesnav-item js-map-switch'):\n",
    "        r1 = re.findall(r\"[A-Za-z]\", div.text.strip())\n",
    "        maps.append(''.join(r1))\n",
    "         \n",
    "    # Get all Game Tables. 1 Game Table = 1 set of 5 players.\n",
    "    # One Game consists of one pair of Game Tables. \n",
    "    # The number of games in a match is determined by the (number of Game Tables/2) - 1\n",
    "    match_stats = []\n",
    "    match_agents = []\n",
    "    for table in soup.find_all('table', class_='wf-table-inset mod-overview'):\n",
    "        # Get player ID\n",
    "        game_stats = []\n",
    "        game_agents = []\n",
    "        for player_id in table.find_all('a', href=True):\n",
    "            game_stats.append(player_id['href'])\n",
    "            \n",
    "        # Get stats per player\n",
    "        for stats in table.find_all('td', class_='mod-stat'):\n",
    "            game_stats.append(stats.text.strip()) \n",
    "            \n",
    "        for div in table.find_all('td', class_='mod-agents'):\n",
    "            for img in div.find_all('img'):\n",
    "                game_agents.append((img.attrs)['title'])\n",
    "            \n",
    "        match_stats.append(game_stats)\n",
    "        match_agents.append(game_agents)\n",
    "        \n",
    "    if (not len(match_stats) or not len(match_agents)):\n",
    "        print(\"Error at \", url)\n",
    "        continue\n",
    "    \n",
    "    # For some reason, the second pair of tables is the Match Overview\n",
    "    # Switch them up by swapping the first pair with the second one.\n",
    "    match_stats[0], match_stats[1] = match_stats[2], match_stats[3]\n",
    "    match_agents[2], match_agents[3] = match_agents[0], match_agents[1]\n",
    "    \n",
    "    \n",
    "    # Get the scores of each game in the match\n",
    "    game_scores = []\n",
    "    for div in soup.find_all('div', class_='vm-stats-game-header'):\n",
    "        for subdiv in div.find_all('div', class_='score'):\n",
    "            game_scores.append(subdiv.text.strip())\n",
    "\n",
    "    # Export match data to CSV File\n",
    "    with open('matches_NA.csv', 'a') as f:\n",
    "        thewriter = writer(f)\n",
    "        try:\n",
    "            data = data + match_stats[0] + match_stats[1]\n",
    "            thewriter.writerow(data)\n",
    "        except:\n",
    "            break\n",
    "    \n",
    "    # Export each games in the match to the CSV file\n",
    "    with open('games_NA.csv', 'a') as f:\n",
    "        thewriter = writer(f)\n",
    "        for i in range(1, int(len(match_stats)/2)):\n",
    "            try:\n",
    "                matchdata = []\n",
    "                matchdata.append(data[0])\n",
    "                matchdata.append(maps[i - 1])\n",
    "\n",
    "                matchdata.append(int(game_scores[(i - 1)*2]))\n",
    "                matchdata.append(int(game_scores[(i - 1)*2 + 1]))\n",
    "                \n",
    "                # Error correction for invalid game scores \n",
    "                if int(game_scores[(i - 1)*2]) == int(game_scores[(i - 1)*2 + 1]):\n",
    "                    continue\n",
    "                elif int(game_scores[(i - 1)*2]) > int(game_scores[(i - 1)*2 + 1]):\n",
    "                    matchdata.append(teams[0])\n",
    "                    matchdata.append(teams[1])\n",
    "                else:\n",
    "                    matchdata.append(teams[1])\n",
    "                    matchdata.append(teams[0])\n",
    "\n",
    "                matchdata = matchdata + match_agents[i*2] + match_stats[i*2] + match_agents[i*2 + 1] + match_stats[i*2 + 1]\n",
    "                thewriter.writerow(matchdata)\n",
    "            except:\n",
    "                break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
